{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational RAG Agent\n",
    "A conversational LLM app using LangChain & Chroma. Built from these tutorials: \n",
    "- [LangChain RAG](https://python.langchain.com/v0.2/docs/tutorials/rag/)\n",
    "- [Conversational RAG](https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/)\n",
    "\n",
    "This exercise builds on the `conversatinal-rag-stateful.ipynb` exercise and adds in:\n",
    "- A retrieval \"agent\" capable of manipulating steps of the process\n",
    "- Tools the agent can access for stored document retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-chroma beautifulsoup4\n",
    "%pip install -qU langchain-openai\n",
    "%pip install python-dotenv\n",
    "%pip install langchain_core\n",
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Enable tracing with LangSmith\n",
    "# LANGCHAIN_API_KEY environment variable is set in .env\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"conversational-rag-agent\"\n",
    "\n",
    "# Set the USER_AGENT environment variable\n",
    "os.environ['USER_AGENT'] = 'conversational-rag-agent'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load, chunk and index source documents to create a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\n",
    "        [\n",
    "            \"https://www.andyfitzgeraldconsulting.com/insights/what-is-information-architecture/\",\n",
    "            \"https://www.andyfitzgeraldconsulting.com/insights/when-to-use-an-ia/\",\n",
    "            \"https://www.andyfitzgeraldconsulting.com/insights/working-with-an-ia/\",\n",
    "            \"https://www.andyfitzgeraldconsulting.com/insights/how-to-hire-an-ia/\",\n",
    "        ]\n",
    "    ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\"article\"),    \n",
    "    )\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(splits, OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Convert retriever into a LangChain tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "ia_info_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"information_architecture_article_retriever\",\n",
    "    \"Searches and returns excerpts from articles about information architecture.\",\n",
    ")\n",
    "tools = [ia_info_tool]\n",
    "\n",
    "# ia_info_tool.invoke(\"When does a project need an information architect?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create agent with conversation memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the tools at your disposal to answer the question. If you \n",
    "don't know the answer, say that you don't know. Use three \n",
    "sentences maximum and keep the answer concise.\"\"\"\n",
    "\n",
    "agent_executor = create_react_agent(llm, tools, state_modifier=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Invoke the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# create a new id each time this cell is run\n",
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "while True:\n",
    "    question = input(\"> \")\n",
    "    if question == \"q\":\n",
    "        break\n",
    "    response = agent_executor.invoke(\n",
    "        {\"messages\": [HumanMessage(content=question)]}, config=config\n",
    "    )\n",
    "    print(response[\"messages\"][-1].content, \"\\n\")\n",
    "\n",
    "# When does a project need information architecture work?\n",
    "# What is information architecture?\n",
    "# When should I hire an information architect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the response object\n",
    "import json\n",
    "\n",
    "print(json.dumps(response, indent=4, default=str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
